+++
# Date this page was created.
date = "2017-08-30"

# Project title.
title = "CarML: Cognitive ARtifacts for Machine Learning"

# Project summary to display on homepage.
summary = "An open source distributed platform allowing people to easily deploy and experiment different Machine Learning / Deep Leaning frameworks and models."

# Optional image to display on homepage (relative to `static/img/` folder).
image_preview = "carml.png"

# Tags: can be used for filtering projects.
# Example: `tags = ["machine-learning", "deep-learning"]`
tags = ["current"]

# Optional external URL for project (replaces project detail page).
external_link = "https://rai-project.github.io/carml"

# Does the project detail page use math formatting?
math = false

# Optional featured image (relative to `static/img/` folder).
[header]
image = "headers/bubbles-wide.jpg"
caption = ":smile:"

+++

The current process of experimenting with different machine learning (ML) packages and deep learning (DL) frameworks as well as their corresponding ML/DL models is, however, daunting. It involves (1) instantiating the  right hardware system, (2) installing the right ML/DL software packages with dependencies, (3) obtaining the right ML/DL models and related dataset, (4) configuring the system, software, and models to work together to run the experiments, and (5) collecting and analyzing experiment results for the needed use case. Most likely, many pages of documentation (if available) must be followed to install one ML and/or DL framework, followed by a process to download and use a particular MD and/or DL model. Not to mention the complexity involved with different hardware system configurations and their interplay with any user's pre-existing system software installation and their complex dependencies.

CarML (Cognitive ARtifacts for Machine Learning) is an open source distributed platform allowing people to easily deploy and experiment different ML/DL frameworks and models, all through a common interface. It allows ML/DL developers to publish and evaluate their models, users to experiment with published models and frameworks, and system architects (who develop underlying hardware systems and infrastructures to support ML/DL workloads) to capture system resource usage to inform future system and hardware configuration.

